{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats, linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from idtxl.bivariate_pid import BivariatePID\n",
    "from idtxl.data import Data\n",
    "\n",
    "from mesostat.metric.dim3d.partialcorr import partial_corr\n",
    "\n",
    "# Append base directory\n",
    "import os,sys\n",
    "rootname = \"conservative-tripartite-testing\"\n",
    "thispath = os.getcwd()\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "import src.null_models_3D as null3D\n",
    "import src.null_test as nulltest\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCorr Funictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decompLabels = ['unq_s1', 'unq_s2']\n",
    "\n",
    "def pcorr(x, y, z):\n",
    "    return {\n",
    "        'unq_s1': partial_corr(x, z, np.array([y])),\n",
    "        'unq_s2': partial_corr(y, z, np.array([x]))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrFuncDict = null3D.discr_method_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing binning-dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valThrDict = None\n",
    "valThrDict = {'unq_s1': None, 'unq_s2': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nData = 10000\n",
    "\n",
    "taskDict = {\n",
    "    'yolo': np.array([0,0,0]),\n",
    "    'norand': np.array([0,0,0.5]),\n",
    "    'randx': np.array([0.5,0,0.5]),\n",
    "    'rand': np.array([0.5,0.5,0.5])\n",
    "}\n",
    "\n",
    "for taskName, params in taskDict.items():\n",
    "    print(taskName)\n",
    "    rezDict = {}\n",
    "\n",
    "    # Do continuous tests\n",
    "    for funcName, func in discrFuncDict.items():\n",
    "        print('-', funcName)\n",
    "        \n",
    "        f_data   = lambda: func(nData, *params)\n",
    "        f_metric = lambda x, y, z: pcorr(x,y,z)\n",
    "\n",
    "        rezDF   = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100)\n",
    "        rezDFsh = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "        nulltest.plot_test_summary(rezDF, rezDFsh, suptitle=funcName, haveEff=False, valThrDict=valThrDict)\n",
    "        suffix = '' if valThrDict is None else '_withThr'\n",
    "        plt.savefig(funcName + '_discr_pcorr_summary_'+taskName+suffix+'.svg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of variance\n",
    "\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_metric_discr = lambda x, y, z: pcorr(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do continuous tests\n",
    "nData = 10000\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': lambda alpha: [0,0,alpha],\n",
    "    'ImpureX': lambda alpha: [alpha,0,alpha],\n",
    "    'Impure' : lambda alpha: [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "#     'H0_adj' : {'unq_s1': 0.718, 'unq_s2': 0.718}\n",
    "#     'H0_adj' : {'unq_s1': 0.5155426964271462, 'unq_s2': 0.5155426964271462}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        # Plot constant thresholds for PureSrc\n",
    "        avgRand = alphaStratName == 'PureSrc'\n",
    "        \n",
    "        f_data_eff = lambda alpha: f_data(nData, *alphaFunc(alpha))\n",
    "        \n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_param_effect(f_data_eff, f_metric_discr, decompLabels, fontsize=12,\n",
    "                                           nStep=1001, nSkipTest=100, nTest=200, alphaRange=(0, 1),\n",
    "                                           avgRand=avgRand, thrMetricDict=thrMetricDict, plotAlphaSq=False)\n",
    "\n",
    "            suffix = 'n_' + str(nData) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_discr_pcorr_scatter_vareff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nData=10000\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    print(fName)\n",
    "    \n",
    "    f_data_eff = lambda alpha: f_data(nData, alpha, alpha, alpha)\n",
    "    nulltest.run_plot_param_effect_test(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                        nStep=10, nTest=400, alphaRange=(0, 2), valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(fName + '_discr_pcorr_vareff_n'+str(nData)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.25\n",
    "\n",
    "# thrLst = [0.6719351345001467,\n",
    "#  0.6146967156250432,\n",
    "#  0.5893340729485583,\n",
    "#  0.5784473458733254,\n",
    "#  0.5641776108079606,\n",
    "#  0.5480398857334239,\n",
    "#  0.536161629340794,\n",
    "#  0.5292341868435549,\n",
    "#  0.5214093689544852,\n",
    "#  0.5155426964271462]\n",
    "\n",
    "# thrDict = dict(zip((10**np.linspace(2, 4, 10)).astype(int), thrLst))\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': [0,0,alpha],\n",
    "    'ImpureX': [alpha,0,alpha],\n",
    "    'Impure' : [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "#     'H0_adj' : {'unq_s1': thrDict, 'unq_s2': thrDict}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        f_data_eff = lambda n: f_data(n, *alphaFunc)\n",
    "\n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_data_effect(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                          nStep=101, nSkipTest=10, nTest=200, pVal=0.01,\n",
    "                                          thrMetricDict=thrMetricDict, fontsize=12)\n",
    "\n",
    "            suffix = 'alpha_' + str(alpha) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_discr_pcorr_scatter_nEff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    print(fName)\n",
    "\n",
    "    f_data_eff = lambda n: f_data(n=n, aX=alpha, aY=alpha, aZ=alpha)\n",
    "    nulltest.run_plot_data_effect_test(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                       nStep=10, nTest=400, valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(fName + '_discr_pcorr_nEff_sig'+str(sig)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test relationship of unique and redundancy for fixed data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Finding max synergy parameters - GridSearch1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mesostat.visualization.mpl_colors import base_colors_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tableauColors = base_colors_rgb(key='tableau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_data_1D = lambda nData, alpha: null3D.discr_red_noisy(nData, alpha, alpha, alpha)\n",
    "nDataLst = (10**np.linspace(2, 4, 10)).astype(int)\n",
    "alphaMaxLst = []\n",
    "thrAdjLst = []\n",
    "thrRandLst = []\n",
    "\n",
    "for nData in nDataLst:\n",
    "    print(nData)\n",
    "    alphaMax, thr = nulltest.run_plot_1D_scan(f_data_1D, f_metric_discr, 'unq_s2', 'unq_s1',\n",
    "                                              varLimits=(0, 1), nData=nData, nStep=100, nTest=100,\n",
    "                                              colorA = tableauColors[1], colorB = tableauColors[0])\n",
    "    \n",
    "    plt.savefig('red_discr_pcorr_1Dscan_unq_n_'+str(nData)+'.svg')\n",
    "    plt.show()\n",
    "    \n",
    "    # Get also shuffle distribution at this alpha\n",
    "    datagen_func_noparam = lambda nData: f_data_1D(nData, alphaMax)\n",
    "    randValues = nulltest.sample_decomp(datagen_func_noparam, f_metric_discr, 'unq_s1',\n",
    "                                        nData=nData, nSample=10000, haveShuffle=True)\n",
    "    \n",
    "    alphaMaxLst += [alphaMax]\n",
    "    thrAdjLst += [thr]\n",
    "    thrRandLst += [np.quantile(randValues, 0.99)]\n",
    "    \n",
    "plt.figure()\n",
    "# plt.plot(nDataLst, alphaMaxLst, label='param')\n",
    "plt.plot(nDataLst, thrAdjLst, label='adjusted', color='purple')\n",
    "plt.plot(nDataLst, thrRandLst, label='shuffle')\n",
    "plt.legend()\n",
    "plt.ylim([0, None])\n",
    "plt.savefig('red_discr_pcorr_1Dscan_unq_summary.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synergistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_data_1D = lambda nData, alpha: null3D.discr_syn_noisy(nData, alpha, alpha, alpha)\n",
    "nDataLst = 1000 * np.arange(1, 11)\n",
    "alphaMaxLst = []\n",
    "thrAdjLst = []\n",
    "thrRandLst = []\n",
    "\n",
    "for nData in nDataLst:\n",
    "    print(nData)\n",
    "    alphaMax, thr = nulltest.run_plot_1D_scan(f_data_1D, f_metric_discr, 'unq_s2', 'unq_s1',\n",
    "                                              varLimits=(0, 1), nData=nData, nStep=100, nTest=100,\n",
    "                                              colorA = tableauColors[1], colorB = tableauColors[0])\n",
    "    \n",
    "    plt.savefig('syn_discr_pcorr_1Dscan_unq_n_'+str(nData)+'.svg')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Get also shuffle distribution at this alpha\n",
    "    datagen_func_noparam = lambda nData: f_data_1D(nData, alphaMax)\n",
    "    randValues = nulltest.sample_decomp(datagen_func_noparam, f_metric_discr, 'unq_s1',\n",
    "                                        nData=nData, nSample=10000, haveShuffle=True)\n",
    "    \n",
    "    alphaMaxLst += [alphaMax]\n",
    "    thrAdjLst += [thr]\n",
    "    thrRandLst += [np.quantile(randValues, 0.99)]\n",
    "    \n",
    "plt.figure()\n",
    "# plt.plot(nDataLst, alphaMaxLst, label='param')\n",
    "plt.plot(nDataLst, thrAdjLst, label='adjusted', color='purple')\n",
    "plt.plot(nDataLst, thrRandLst, label='shuffle')\n",
    "plt.legend()\n",
    "plt.ylim([0, None])\n",
    "plt.savefig('syn_discr_pcorr_1Dscan_unq_summary.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3QT5",
   "language": "python",
   "name": "py3qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
