{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from idtxl.bivariate_pid import BivariatePID\n",
    "from idtxl.data import Data\n",
    "\n",
    "from mesostat.utils.decorators import redirect_stdout\n",
    "from mesostat.visualization.mpl_colors import base_colors_rgb\n",
    "from mesostat.metric.dim3d.npeet_pid import pid_barrett\n",
    "\n",
    "# Append base directory\n",
    "import os,sys\n",
    "rootname = \"conservative-tripartite-testing\"\n",
    "thispath = os.getcwd()\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "import src.null_models_3D as null3D\n",
    "import src.null_test as nulltest\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefixPath = 'figs/cont_mmi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID Funictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decompLabels = ['unq_s1', 'unq_s2', 'shd_s1_s2', 'syn_s1_s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pid(x, y, z):\n",
    "    return dict(zip(decompLabels, pid_barrett(x,y,z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contFuncDict = null3D.cont_method_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing binning-dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valThrDict = None\n",
    "# valThrDict = {'unq_s1': 0.08, 'unq_s2': 0.08, 'shd_s1_s2': None, 'syn_s1_s2': 0.16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taskDict = {\n",
    "    'yolo': np.array([0,0,0]),\n",
    "    'norand': np.array([0,0,0.5]),\n",
    "    'randx': np.array([0.5,0,0.5]),\n",
    "    'rand': np.array([0.5,0.5,0.5])\n",
    "}\n",
    "\n",
    "for taskName, params in taskDict.items():\n",
    "    print(taskName)\n",
    "    rezDict = {}\n",
    "\n",
    "    # Do continuous tests\n",
    "    for funcName, func in contFuncDict.items():\n",
    "        print('-', funcName)\n",
    "        \n",
    "        f_data   = lambda: func(10000, *params)\n",
    "\n",
    "        rezDF   = nulltest.run_tests(f_data, pid, decompLabels, nTest=100)\n",
    "        rezDFsh = nulltest.run_tests(f_data, pid, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "        nulltest.plot_test_summary(rezDF, rezDFsh, suptitle=funcName, haveEff=False, valThrDict=valThrDict)\n",
    "        suffix = '' if valThrDict is None else '_withThr'\n",
    "        plt.savefig(prefixPath + funcName + '_cont_mmi_summary_'+taskName+suffix+'.svg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of variance\n",
    "\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do continuous tests\n",
    "nData = 10000\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': lambda alpha: [0,0,alpha],\n",
    "    'ImpureX': lambda alpha: [alpha,0,alpha],\n",
    "    'Impure' : lambda alpha: [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "    'H0_adj' : {'unq_s1': 0.04, 'unq_s2': 0.04, 'shd_s1_s2': 0.0252, 'syn_s1_s2': 1.08}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        # Plot constant thresholds for PureSrc\n",
    "        avgRand = alphaStratName == 'PureSrc'\n",
    "        \n",
    "        f_data_eff = lambda alpha: f_data(nData, *alphaFunc(alpha))\n",
    "        \n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_param_effect(f_data_eff, pid, decompLabels, fontsize=12,\n",
    "                                           nStep=1001, nSkipTest=100, nTest=200, alphaRange=(0.01, 1),\n",
    "                                           avgRand=avgRand, thrMetricDict=thrMetricDict, plotAlphaSq=False)\n",
    "\n",
    "            suffix = 'n_' + str(nData) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(prefixPath + fName + '_cont_mmi_scatter_vareff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nData=10000\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    print(fName)\n",
    "    \n",
    "    f_data_eff = lambda alpha: f_data(n=nData, aX=alpha, aY=alpha, aZ=alpha)\n",
    "    nulltest.run_plot_param_effect_test(f_data_eff, pid, decompLabels,\n",
    "                                        nStep=10, nTest=400, alphaRange=(0, 1), valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(prefixPath + fName + '_r2_vareff_n'+str(nData)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nData=10000\n",
    "f_data = lambda alpha: null3D.cont_xor_noisy(n=nData, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "nulltest.run_plot_param_effect_test_single(f_data, pid, decompLabels, 0, nTest=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of number of samples\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.25\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': [0,0,alpha],\n",
    "    'ImpureX': [alpha,0,alpha],\n",
    "    'Impure' : [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "# Load calculated adjusted thresholds\n",
    "nDataLstRed, thrRandLstRed, thrAdjLstRed = np.loadtxt(prefixPath + 'cont_mmi_munq_1Dscan_red_summary.csv', dtype=float)\n",
    "nDataLstUnq, thrRandLstUnq, thrAdjLstUnq = np.loadtxt(prefixPath + 'cont_mmi_mred_1Dscan_unq_summary.csv', dtype=float)\n",
    "nDataLstSyn, thrRandLstSyn, thrAdjLstSyn = np.loadtxt(prefixPath + 'cont_mmi_mred_1Dscan_syn_summary.csv', dtype=float)\n",
    "thrDictRed = dict(zip(nDataLstRed, thrAdjLstRed))\n",
    "thrDictUnq = dict(zip(nDataLstUnq, thrAdjLstUnq))\n",
    "thrDictSyn = dict(zip(nDataLstSyn, thrAdjLstSyn))\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "    'H0_adj' : {'unq_s1': thrDictUnq, 'unq_s2': thrDictUnq, 'shd_s1_s2': thrDictRed, 'syn_s1_s2': thrDictSyn}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        f_data_eff = lambda n: f_data(n, *alphaFunc)\n",
    "\n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_data_effect(f_data_eff, pid, decompLabels,\n",
    "                                          nStep=101, nSkipTest=10, nTest=200, pVal=0.01,\n",
    "                                          thrMetricDict=thrMetricDict, fontsize=12)\n",
    "\n",
    "            suffix = 'alpha_' + str(alpha) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(prefixPath + fName + '_cont_mmi_scatter_nEff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    print(fName)\n",
    "\n",
    "    f_data_eff = lambda n: f_data(n=n, aX=alpha, aY=alpha, aZ=alpha)\n",
    "    nulltest.run_plot_data_effect_test(f_data_eff, pid, decompLabels,\n",
    "                                       nStep=10, nTest=400, valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(prefixPath + fName + '_mmi_nEff_sig'+str(sig)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing conservative thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tableauColors = base_colors_rgb(key='tableau')\n",
    "tableauMap = dict(zip(decompLabels, tableauColors[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Testing all noise parameter combinations\n",
    "\n",
    "We try to find patterns for lines in 3D where largest FP emerge\n",
    "\n",
    "### MRed -> Unq\n",
    "\n",
    "Find noise fraction combination that causes highest FP unique atoms\n",
    "* NOTE: Scan only over $p_x = p_y$. In case of mismatched noise fractions FP unique arises naturally, but this is a problem in experimental design rather than testing so it is not included in this testing procedure.\n",
    "* NOTE 2: Actual assumption in this case is that noise is equal in all tested channels. Hence it is ok to simply test $p_x = p_y = p_z$ only\n",
    "\n",
    "**Intermediate Conclusion**: Largest noise for $p_x=p_y=0.5$, $p_z = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_metric_cont = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data_2D = lambda nData, a, b: null3D.cont_red_noisy(nData, a, a, b)\n",
    "\n",
    "paramArr3D, dataArr3D = nulltest.run_scan_bare(f_data_2D, f_metric_cont, 2, decompLabels, varLimits=(0, 1),\n",
    "                                               nData=5000, nStep=30, nTest=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.print_scan_max(paramArr3D, dataArr3D, 'unq_s1', decompLabels, nMax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.plot_scan_2D(dataArr3D, 'unq_s1', decompLabels, 30, (0,1), fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRed -> Syn\n",
    "\n",
    "**Intermediate Conclusion**: OMG, the FP likely largest for zero noise, where theoretically it is infinite, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data_3D = lambda nData, a, b, c: null3D.cont_red_noisy(nData, a, b, c)\n",
    "\n",
    "paramArr3D, dataArr3D = nulltest.run_scan_bare(f_data_3D, f_metric_cont, 3, decompLabels, varLimits=(0.01, 0.1),\n",
    "                                               nData=5000, nStep=10, nTest=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.print_scan_max(paramArr3D, dataArr3D, 'syn_s1_s2', decompLabels, nMax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.plot_scan_3D_2D_bytrg(paramArr3D, dataArr3D, 'syn_s1_s2', decompLabels, 0, 10, (0.01, 0.1),\n",
    "                               fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUnq -> Red\n",
    "\n",
    "**Intermediate Conclusion**: Radially symmetric, lower noise better, possibly insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_data_2D = lambda nData, a, b: null3D.cont_unq_noisy(nData, a, 0, b)\n",
    "\n",
    "paramArr2D, dataArr2D = nulltest.run_scan_bare(f_data_2D, f_metric_cont, 2, decompLabels, varLimits=(0, 1),\n",
    "                                               nData=5000, nStep=30, nTest=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.plot_scan_2D(dataArr2D, 'shd_s1_s2', decompLabels, 30, (0,1), fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUnq -> Syn\n",
    "\n",
    "**Intermediate Conclusion**: Radially symmetric, lower noise better, possibly insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.plot_scan_2D(dataArr2D, 'syn_s1_s2', decompLabels, 30, (0,1), fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSyn -> Red\n",
    "\n",
    "**Intermediate Conclusion**:  Erratic, insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_data_3D = lambda nData, a, b, c: null3D.cont_xor_noisy(nData, a, b, c)\n",
    "\n",
    "paramArr3D, dataArr3D = nulltest.run_scan_bare(f_data_3D, f_metric_cont, 3, decompLabels, varLimits=(0, 1),\n",
    "                                               nData=5000, nStep=10, nTest=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.print_scan_max(paramArr3D, dataArr3D, 'shd_s1_s2', decompLabels, nMax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulltest.plot_scan_3D_2D_bytrg(paramArr3D, dataArr3D, 'shd_s1_s2', decompLabels, 0, 10, (0, 1),\n",
    "                               fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSyn -> Unq\n",
    "\n",
    "**Intermediate Conclusion**: Erratic, insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nulltest.print_scan_max(paramArr3D, dataArr3D, 'unq_s1', decompLabels, nMax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nulltest.plot_scan_3D_2D_bytrg(paramArr3D, dataArr3D, 'unq_s1', decompLabels, 2, 10, (0, 1),\n",
    "                               fontsize=16, haveColorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Actual testing\n",
    "\n",
    "Have to assume minimal noise as 0.01, otherwise get infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loopLst = [\n",
    "    ['red', 'unq', 'shd_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['red', 'syn', 'shd_s1_s2', 'syn_s1_s2', lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['unq', 'red', 'unq_s1',    'shd_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['unq', 'syn', 'unq_s1',    'syn_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['syn', 'red', 'syn_s1_s2', 'shd_s1_s2', lambda nData, alpha: null3D.cont_xor_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['syn', 'unq', 'syn_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_xor_noisy(nData, alpha, alpha, alpha)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefixPath = 'figs/cont_mmi/'\n",
    "\n",
    "nSample = 1000\n",
    "nDataLst = (10**np.linspace(2, 4, 10)).astype(int)\n",
    "# nDataLst = [10000]\n",
    "for labelA, labelB, atomA, atomB, f_data_1D in loopLst:\n",
    "    prefix = prefixPath + 'cont_mmi_m'+labelA+'_1Dscan_'+labelB\n",
    "    thrAdjLst = []\n",
    "    thrRandLst = []\n",
    "    \n",
    "    for nData in nDataLst:\n",
    "        paramArr1D, dataArr1D = nulltest.run_scan_bare(f_data_1D, f_metric_cont, 1, decompLabels,\n",
    "                                                       varLimits=(0.01, 1), nData=nData, nStep=100, nTest=20)\n",
    "\n",
    "        thrAdj = nulltest.resample_get_thr(f_data_1D, f_metric_cont, atomB, decompLabels, paramArr1D, dataArr1D,\n",
    "                                           nData=nData, nTestResample=nSample, pVal=0.01, haveShuffle=False)\n",
    "\n",
    "        thrShuffle = nulltest.resample_get_thr(f_data_1D, f_metric_cont, atomB, decompLabels, paramArr1D, dataArr1D,\n",
    "                                               nData=nData, nTestResample=nSample, pVal=0.01, haveShuffle=True)\n",
    "        \n",
    "        print(nData, thrAdj, thrShuffle)\n",
    "\n",
    "        savename = prefix+'_n_'+str(nData)+'.svg'\n",
    "        nulltest.plot_scan_1D(paramArr1D, dataArr1D, [atomA, atomB], atomB, decompLabels,\n",
    "                              maxThr=thrAdj, colorDict=tableauMap, savename=savename,\n",
    "                              fontsize=16, xlabel='Noise Fraction', ylabel='Nats')\n",
    "        plt.close()\n",
    "\n",
    "        thrAdjLst += [thrAdj]\n",
    "        thrRandLst += [thrShuffle]\n",
    "\n",
    "    plt.figure()\n",
    "#     plt.plot(nDataLst, alphaMaxLst)\n",
    "    plt.plot(nDataLst, thrAdjLst, label='adjusted', color='purple')\n",
    "    plt.plot(nDataLst, thrRandLst, label='shuffle')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, None])\n",
    "    plt.savefig(prefix + '_summary.svg')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results to file\n",
    "    rezArr = np.array([nDataLst, thrRandLst, thrAdjLst])\n",
    "    np.savetxt(prefix + '_summary.csv', rezArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Determining Scatter Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrDataMethodDict = {\n",
    "    'Cont' : null3D.cont_method_dict(),\n",
    "    'Discr' : null3D.discr_method_dict()\n",
    "}\n",
    "\n",
    "atomCombList = {\n",
    "    ['shd_s1_s2', 'unq_s1'],\n",
    "    ['shd_s1_s2', 'syn_s1_s2'],\n",
    "    ['unq_s1',    'shd_s1_s2'],\n",
    "    ['unq_s1',    'syn_s1_s2'],\n",
    "    ['syn_s1_s2', 'shd_s1_s2'],\n",
    "    ['syn_s1_s2', 'unq_s1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for discrKey, dataMethodsDict in discrDataMethodDict.items():\n",
    "    for fDataLabel, f_data_3D in dataMethodsDict.items():\n",
    "        for atomA, atomB in atomCombList:\n",
    "            nulltest.run_plot_scatter_explore(f_data_3D, f_metric_cont,\n",
    "                                              atomA, atomB, 3,\n",
    "                                              varLimits=(0, 1), nData=1000, nTestDim=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining testing thresholds for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only test combinations that matter\n",
    "loopLst = [\n",
    "    ['red', 'unq', 'shd_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['red', 'syn', 'shd_s1_s2', 'syn_s1_s2', lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, 0)],\n",
    "    ['unq', 'red', 'unq_s1',    'shd_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)]\n",
    "]\n",
    "\n",
    "# TEX + AUD\n",
    "nDataLst = [1315, 1209, 3967, 1910, 1724, 4784, 1307, 1324, 5191, 1132, 1014, 3111] + \\\n",
    "           [1070, 510, 2498, 1274, 735, 3407, 1918, 953, 4472, 1008, 630, 2320] + \\\n",
    "           [564, 591, 605, 643, 812, 1040, 1131, 1166, 1263, 1317, 1406, 1412, 1448,\n",
    "            1525, 1668, 1974, 2438, 2767, 2891, 3228, 3278, 7106, 8209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for labelA, labelB, atomA, atomB, f_data_1D in loopLst:\n",
    "    for nData in nDataLst:\n",
    "        key = labelA + '_' + labelB + '_' + str(nData)\n",
    "        with h5py.File('pid_rand_dist.h5', 'a') as h5f:\n",
    "            if key in h5f.keys():\n",
    "                print(key, 'already done')\n",
    "                continue\n",
    "                \n",
    "        print(key)\n",
    "        \n",
    "        randValues = nulltest.run_1D_scan_bare(f_data_1D, f_metric_cont, atomB,\n",
    "                                               varLimits=(0, 1), nData=nData,\n",
    "                                               nStep=100, nTest=100, nTestResample=10000)[1]\n",
    "        \n",
    "        \n",
    "        with h5py.File('pid_rand_dist.h5', 'a') as h5f:\n",
    "            h5f[key] = randValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3QT5",
   "language": "python",
   "name": "py3qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
