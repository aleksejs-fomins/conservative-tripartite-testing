{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended root directory /home/alyosha/work/git/conservative-tripartite-testing\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from idtxl.bivariate_pid import BivariatePID\n",
    "from idtxl.data import Data\n",
    "\n",
    "from mesostat.utils.decorators import redirect_stdout\n",
    "from mesostat.visualization.mpl_colors import base_colors_rgb\n",
    "\n",
    "# Append base directory\n",
    "import os,sys\n",
    "rootname = \"conservative-tripartite-testing\"\n",
    "thispath = os.getcwd()\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "import src.null_models_3D as null3D\n",
    "import src.null_test as nulltest\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PID Funictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompLabels = ['unq_s1', 'unq_s2', 'shd_s1_s2', 'syn_s1_s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data_1D(data, nBins):\n",
    "    boundaries = np.quantile(data, np.linspace(0, 1, nBins + 1))\n",
    "    boundaries[-1] += 1.0E-10\n",
    "    return np.digitize(data, boundaries, right=False) - 1\n",
    "\n",
    "\n",
    "def pid_bin(x, y, z, nBins=4):\n",
    "    dataEff = np.array([\n",
    "        bin_data_1D(x, nBins),\n",
    "        bin_data_1D(y, nBins),\n",
    "        bin_data_1D(z, nBins)\n",
    "    ])\n",
    "\n",
    "    return pid(dataEff)\n",
    "\n",
    "\n",
    "@redirect_stdout\n",
    "def pid(dataPS):\n",
    "    settings = {'pid_estimator': 'TartuPID', 'lags_pid': [0, 0]}\n",
    "\n",
    "    dataIDTxl = Data(dataPS, dim_order='ps', normalise=False)\n",
    "    pid = BivariatePID()\n",
    "    rez = pid.analyse_single_target(settings=settings, data=dataIDTxl, target=2, sources=[0, 1])\n",
    "    rezTrg = rez.get_single_target(2)\n",
    "\n",
    "    # Getting rid of negative and very low positive PID's.\n",
    "    # Statistical tests behave unexplectedly - perhaps low values contaminated by roundoff errors?\n",
    "    return {k : np.clip(rezTrg[k], 1.0E-6, None) for k in decompLabels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Noisy Redundant Scenario\n",
    "\n",
    "We want to check if white noise added to a purely redundant scenario results in correct identification of redundancy\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = T + \\nu_Z$$\n",
    "\n",
    "where $Y$ is the target of $X$ and $Z$, and\n",
    "\n",
    "$$T \\sim \\mathcal{N}(0, 1)$$\n",
    "$$\\nu_X, \\nu_Y, \\nu_Z \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "and $\\sigma$ is a free parameter, denoting the Noise-To-Signal ratio. So the signal should be a mixture of redundant signal and white noise.\n",
    "\n",
    "Since the signal is continuous, we bin it using different bin counts.\n",
    "\n",
    "### Noisy Unique Scenario\n",
    "\n",
    "Same as before, but\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = \\nu_Z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Redundant Scenario - Discrete Case\n",
    "\n",
    "It is important to test if false positives are caused by binning, or are an intrinsic property of the noise in the covariate. Here I propose a discretized noisy redundancy model. Instead of added noise, each variable has a random chance to produce the redundant outcome or a purely random outcome.\n",
    "\n",
    "$$X \\sim A_X \\nu_X + (1 - A_X) T $$\n",
    "$$Y \\sim A_Y \\nu_Y + (1 - A_Y) T $$\n",
    "$$Z \\sim A_Z \\nu_Z + (1 - A_Z) T $$\n",
    "\n",
    "where\n",
    "\n",
    "$$T, \\nu_X, \\nu_Y, \\nu_Z \\sim Ber(0.5) $$\n",
    "$$A_X \\sim Ber(\\alpha_X)$$\n",
    "$$A_Y \\sim Ber(\\alpha_Y)$$\n",
    "$$A_Z \\sim Ber(\\alpha_Z)$$\n",
    "\n",
    "and $\\alpha_X, \\alpha_Y, \\alpha_Z \\in [0, 1]$ are flexible.\n",
    "\n",
    "So, $\\alpha = 0$ means purely redundant signal, and $\\alpha=1$ means purely noisy signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrFuncDict = null3D.discr_method_dict()\n",
    "contFuncDict = null3D.cont_method_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing binning-dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valThrDict = None\n",
    "valThrDict = {'unq_s1': 0.08, 'unq_s2': 0.08, 'shd_s1_s2': None, 'syn_s1_s2': 0.16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taskDict = {\n",
    "    'yolo':    0.5*np.array([0,0,0]),\n",
    "    'norand':  0.5*np.array([0,0,1]),\n",
    "    'randx':   0.5*np.array([1,0,1]),\n",
    "    'rand':    0.5*np.array([1,1,1])\n",
    "}\n",
    "\n",
    "for taskName, params in taskDict.items():\n",
    "    print(taskName)\n",
    "    rezDict = {}\n",
    "\n",
    "    # Do continuous tests\n",
    "    for funcName, func in contFuncDict.items():\n",
    "        print('-', funcName)\n",
    "        \n",
    "#         for nBins in range(2, 6):\n",
    "        for nBins in [2]:\n",
    "            f_data   = lambda: func(10000, *params)\n",
    "            f_metric = lambda x, y, z: pid_bin(x,y,z, nBins)\n",
    "\n",
    "            rezDF   = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100)\n",
    "            rezDFsh = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "            rezDict[(funcName, nBins)] = (rezDF, rezDFsh)\n",
    "                        \n",
    "    # Do discrete tests\n",
    "    f_metric = lambda x, y, z: pid(np.array([x,y,z]))\n",
    "    for funcName, func in discrFuncDict.items():\n",
    "        f_data = lambda: func(10000, *(0.5*params))\n",
    "        rezDF   = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100)\n",
    "        rezDFsh = nulltest.run_tests(f_data, f_metric, decompLabels, nTest=100, haveShuffle=True)\n",
    "\n",
    "        rezDict[('red_discr', 2)] = (rezDF, rezDFsh)\n",
    "\n",
    "    for k, v in rezDict.items():\n",
    "        print(k)\n",
    "        funcName, nBin = k\n",
    "        rezDF, rezDFsh = v\n",
    "\n",
    "        nulltest.plot_test_summary(rezDF, rezDFsh, suptitle=funcName, haveEff=False, valThrDict=valThrDict)\n",
    "        suffix = '' if valThrDict is None else '_withThr'\n",
    "        plt.savefig(funcName + '_pid_nbin'+str(nBin)+'_summary_'+taskName+suffix+'.png', dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of variance\n",
    "\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBin = 2\n",
    "f_metric_cont = lambda x, y, z: pid_bin(x,y,z, nBin)\n",
    "f_metric_discr = lambda x, y, z: pid(np.array([x,y,z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do continuous tests\n",
    "nData = 10000\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': lambda alpha: [0,0,alpha],\n",
    "    'ImpureX': lambda alpha: [alpha,0,alpha],\n",
    "    'Impure' : lambda alpha: [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "#     'H0_adj' : {'unq_s1': 0.08, 'unq_s2': 0.08, 'shd_s1_s2': None, 'syn_s1_s2': 0.16}\n",
    "    'H0_adj' : {'unq_s1': 0.02275646333281051, 'unq_s2': 0.02275646333281051,\n",
    "                'shd_s1_s2': 0.0004156815533111131, 'syn_s1_s2': 0.15474468603745337}\n",
    "}\n",
    "\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        \n",
    "        f_data_eff = lambda alpha: f_data(nData, *alphaFunc(alpha))\n",
    "        \n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_param_effect(f_data_eff, f_metric_cont, decompLabels,\n",
    "                                           nStep=1001, nSkipTest=100, nTest=200, alphaRange=(0, 1),\n",
    "                                           thrMetricDict=thrMetricDict, plotAlphaSq=False, fontsize=12)\n",
    "\n",
    "            suffix = 'n_' + str(nData) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_pid_cont_nBin_'+str(nBin)+'_scatter_vareff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nData=10000\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    print(fName)\n",
    "    \n",
    "    f_data_eff = lambda alpha: f_data(n=nData, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "    nulltest.run_plot_param_effect_test(f_data_eff, f_metric_cont, decompLabels,\n",
    "                                        nStep=10, nTest=400, alphaRange=(0, 2), valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(fName + '_pid_nBin2_vareff_n'+str(nData)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nData=10000\n",
    "f_data = lambda alpha: null3D.cont_xor_noisy(n=nData, sigX=alpha, sigY=alpha, sigZ=alpha)\n",
    "nulltest.run_plot_param_effect_test_single(f_data, f_metric_cont, decompLabels, 0, nTest=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do discrete tests\n",
    "nData = 10000\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': lambda alpha: [0,0,alpha],\n",
    "    'ImpureX': lambda alpha: [alpha,0,alpha],\n",
    "    'Impure' : lambda alpha: [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "    'H0_adj' : {'unq_s1': 0.584222767696213, 'unq_s2': 0.584222767696213, 'shd_s1_s2': None, 'syn_s1_s2': 0.21158892644164767}\n",
    "}\n",
    "\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        \n",
    "        f_data_eff = lambda alpha: f_data(nData, *alphaFunc(alpha))\n",
    "        \n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_param_effect(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                           nStep=1001, nSkipTest=100, nTest=200, alphaRange=(0, 1),\n",
    "                                           thrMetricDict=thrMetricDict, fontsize=12)\n",
    "\n",
    "            suffix = 'n_' + str(nData) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_pid_discr_nBin_'+str(nBin)+'_scatter_vareff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nData=10000\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    f_data_eff = lambda alpha: f_data(nData=nData, alphaX=alpha, alphaY=alpha, alphaZ=alpha)\n",
    "    nulltest.run_plot_param_effect_test(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                        nStep=10, nTest=400, alphaRange=(0, 1), valThrDict=valThrDict)\n",
    "\n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(fName + '_pid_vareff_n'+str(nData)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of number of samples\n",
    "Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.25\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': [0,0,alpha],\n",
    "    'ImpureX': [alpha,0,alpha],\n",
    "    'Impure' : [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "nDataArr = (10**np.linspace(2, 4, 10)).astype(int)\n",
    "thrLstUnq = [0.2110814493379376, 0.16689265970521838, 0.13685690308881257, 0.11218595017528467, 0.07860180308826488, 0.06210094806194508, 0.0526950184150174, 0.040739636899229006, 0.029856912086735292, 0.02275646333281051]\n",
    "thrLstRed = [0.04195798086977931, 0.03047641966741261, 0.01652790508850032, 0.012095615389103559, 0.0066037386073174624, 0.003432593102097955, 0.0018820360731625003, 0.001559288121841136, 0.0007872659689172739, 0.0004156815533111131]\n",
    "thrLstSyn = [0.22514955588715468, 0.21503139471261873, 0.19561667035009186, 0.18203585308711429, 0.172750706469084, 0.16579693515602625, 0.16096080804655502, 0.1590930839954668, 0.1559111008893145, 0.15474468603745337]\n",
    "\n",
    "thrDictUnq = dict(zip(nDataArr, thrLstUnq))\n",
    "thrDictRed = dict(zip(nDataArr, thrLstRed))\n",
    "thrDictSyn = dict(zip(nDataArr, thrLstSyn))\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "#     'H0_adj' : {'unq_s1': 0.08, 'unq_s2': 0.08, 'shd_s1_s2': None, 'syn_s1_s2': 0.16}\n",
    "    'H0_adj' : {'unq_s1': thrDictUnq, 'unq_s2': thrDictUnq, 'shd_s1_s2': thrDictRed, 'syn_s1_s2': thrDictSyn}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        f_data_eff = lambda n: f_data(n, *alphaFunc)\n",
    "\n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_data_effect(f_data_eff, f_metric_cont, decompLabels,\n",
    "                                          nStep=101, nSkipTest=10, nTest=200, pVal=0.01,\n",
    "                                          thrMetricDict=thrMetricDict, fontsize=12)\n",
    "\n",
    "            suffix = 'alpha_' + str(alpha) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_pid_cont_nBin_'+str(nBin)+'_scatter_nEff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "for fName, f_data in contFuncDict.items():\n",
    "    print(fName)\n",
    "\n",
    "    f_data_eff = lambda n: f_data(n=n, aX=alpha, aY=alpha, aZ=alpha)\n",
    "    nulltest.run_plot_data_effect_test(f_data_eff, f_metric_cont, decompLabels,\n",
    "                                       nStep=10, nTest=400, valThrDict=valThrDict)\n",
    "    \n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig(fName + '_pid_nBin2_nEff_sig'+str(sig)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.25\n",
    "\n",
    "alphaStratDict = {\n",
    "    'PureSrc': [0,0,alpha],\n",
    "    'ImpureX': [alpha,0,alpha],\n",
    "    'Impure' : [alpha,alpha,alpha],\n",
    "}\n",
    "\n",
    "nDataArr = (10**np.linspace(2, 4, 10)).astype(int)\n",
    "thrLstUnq = [0.7574340361396945, 0.720947418015235, 0.727724170531202, 0.8272464705411215, 0.6906704631336307, 0.5872202030236291, 0.5028266540646666, 0.6524915661572469, 0.4263081662581513, 0.584222767696213]\n",
    "thrLstSyn = [0.2575941657906616, 0.24601433159452815, 0.24779080391562125, 0.22500548226295516, 0.22521972151841443, 0.223708920760494, 0.20122868167962196, 0.2080724784934243, 0.20612904133142615, 0.21158892644164767]\n",
    "\n",
    "thrDictUnq = dict(zip(nDataArr, thrLstUnq))\n",
    "thrDictSyn = dict(zip(nDataArr, thrLstSyn))\n",
    "\n",
    "thrMetricDictDict = {\n",
    "    'H0_orig' : None,\n",
    "#     'H0_adj' : {'unq_s1': 0.75, 'unq_s2': 0.75, 'shd_s1_s2': None, 'syn_s1_s2': 0.22}\n",
    "    'H0_adj' : {'unq_s1': thrDictUnq, 'unq_s2': thrDictUnq, 'shd_s1_s2': None, 'syn_s1_s2': thrDictSyn}\n",
    "}\n",
    "\n",
    "\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    for alphaStratName, alphaFunc in alphaStratDict.items():\n",
    "        f_data_eff = lambda n: f_data(n, *alphaFunc)\n",
    "\n",
    "        for h0type, thrMetricDict in thrMetricDictDict.items():\n",
    "            print(fName, alphaStratName, h0type)\n",
    "\n",
    "            nulltest.run_plot_data_effect(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                          nStep=101, nSkipTest=10, nTest=200, pVal=0.01,\n",
    "                                          thrMetricDict=thrMetricDict, fontsize=12)\n",
    "\n",
    "            suffix = 'alpha_' + str(alpha) + '_' + alphaStratName + '_' + h0type\n",
    "\n",
    "            plt.savefig(fName + '_pid_discr_nBin_'+str(nBin)+'_scatter_nEff_'+suffix+'.svg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "for fName, f_data in discrFuncDict.items():\n",
    "    f_data_eff = lambda n: f_data(nData=n, aX=alpha, aY=alpha, aZ=alpha)\n",
    "    nulltest.run_plot_data_effect_test(f_data_eff, f_metric_discr, decompLabels,\n",
    "                                       nStep=10, nTest=400, valThrDict=valThrDict)\n",
    "\n",
    "    suffix = '' if valThrDict is None else '_withThr'\n",
    "    plt.savefig('redDiscr_pid_nEff_alpha'+str(alpha)+suffix+'.png', dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relationship of synergy and redundancy for fixed data size\n",
    "\n",
    "#### 1. Finding max synergy parameters - GridSearch3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nData in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nData)\n",
    "    nulltest.run_gridsearch_3D(null3D.cont_red_noisy, f_metric_cont, 'syn_s1_s2',\n",
    "                              varLimits=(0, 2), nData=nData, nStep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for nData in [1000, 3000, 5000, 7000, 10000]:\n",
    "    print(nData)\n",
    "    nulltest.run_gridsearch_3D(null3D.discr_red_noisy, f_metric_discr, 'syn_s1_s2',\n",
    "                              varLimits=(0, 1), nData=nData, nStep=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Finding max synergy parameters - GridSearch1D\n",
    "\n",
    "Previous analysis found that in all cases maximal synergy is located at the diagonal $\\alpha_x = \\alpha_y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableauColors = base_colors_rgb(key='tableau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableauMap = {\n",
    "    'unq' : tableauColors[0],\n",
    "    'red' : tableauColors[2],\n",
    "    'syn' : tableauColors[3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loopDict = {\n",
    "    'Cont': [\n",
    "        ['red', 'unq', 'shd_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['red', 'syn', 'shd_s1_s2', 'syn_s1_s2', lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, 0)],\n",
    "        ['unq', 'red', 'unq_s1',    'shd_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['unq', 'syn', 'unq_s1',    'syn_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['syn', 'red', 'syn_s1_s2', 'shd_s1_s2', lambda nData, alpha: null3D.cont_xor_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['syn', 'unq', 'syn_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_xor_noisy(nData, alpha, alpha, alpha)]\n",
    "    ],\n",
    "    'Discr' : [\n",
    "        ['red', 'unq', 'shd_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.discr_red_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['red', 'syn', 'shd_s1_s2', 'syn_s1_s2', lambda nData, alpha: null3D.discr_red_noisy(nData, alpha, alpha, 0)],\n",
    "        ['unq', 'red', 'unq_s1',    'shd_s1_s2', lambda nData, alpha: null3D.discr_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['unq', 'syn', 'unq_s1',    'syn_s1_s2', lambda nData, alpha: null3D.discr_unq_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['syn', 'red', 'syn_s1_s2', 'shd_s1_s2', lambda nData, alpha: null3D.discr_syn_noisy(nData, alpha, alpha, alpha)],\n",
    "        ['syn', 'unq', 'syn_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.discr_syn_noisy(nData, alpha, alpha, alpha)]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nDataLst = (10**np.linspace(2, 4, 10)).astype(int)\n",
    "\n",
    "for discrKey, loopLst in loopDict.items():\n",
    "    for labelA, labelB, atomA, atomB, f_data_1D in loopLst:\n",
    "        prefix = labelA+discrKey+'_pid_1Dscan_'+labelB\n",
    "        print(prefix)\n",
    "\n",
    "        alphaMaxLst = []\n",
    "        thrAdjLst = []\n",
    "        thrRandLst = []\n",
    "\n",
    "        for nData in nDataLst:\n",
    "            print('--', nData)\n",
    "            alphaMax, thr = nulltest.run_plot_1D_scan(f_data_1D, f_metric_cont, atomA, atomB,\n",
    "                                                      varLimits=(0, 1), nData=nData, nStep=100, nTest=100,\n",
    "                                                      colorA = tableauMap[labelA], colorB = tableauMap[labelB])\n",
    "            plt.savefig(prefix+'_n_'+str(nData)+'.svg')\n",
    "            plt.show()\n",
    "            \n",
    "            # Get also shuffle distribution at this alpha\n",
    "            datagen_func_noparam = lambda nData: f_data_1D(nData, alphaMax)\n",
    "            randValues = nulltest.sample_decomp(datagen_func_noparam, f_metric_cont, atomB,\n",
    "                                                nData=nData, nSample=10000, haveShuffle=True)\n",
    "\n",
    "            alphaMaxLst += [alphaMax]\n",
    "            thrAdjLst += [thr]\n",
    "            thrRandLst += [np.quantile(randValues, 0.99)]\n",
    "\n",
    "        plt.figure()\n",
    "#         plt.plot(nDataLst, alphaMaxLst)\n",
    "        plt.plot(nDataLst, thrAdjLst, label='adjusted', color='purple')\n",
    "        plt.plot(nDataLst, thrRandLst, label='shuffle')\n",
    "        plt.legend()\n",
    "        plt.ylim([0, None])\n",
    "        plt.savefig(prefix + '_summary.svg')\n",
    "        plt.show()\n",
    "        \n",
    "        print(thrAdjLst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Determining Scatter Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrDataMethodDict = {\n",
    "    'Cont' : null3D.cont_method_dict(),\n",
    "    'Discr' : null3D.discr_method_dict()\n",
    "}\n",
    "\n",
    "atomCombList = {\n",
    "    ['shd_s1_s2', 'unq_s1'],\n",
    "    ['shd_s1_s2', 'syn_s1_s2'],\n",
    "    ['unq_s1',    'shd_s1_s2'],\n",
    "    ['unq_s1',    'syn_s1_s2'],\n",
    "    ['syn_s1_s2', 'shd_s1_s2'],\n",
    "    ['syn_s1_s2', 'unq_s1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for discrKey, dataMethodsDict in discrDataMethodDict.items():\n",
    "    for fDataLabel, f_data_3D in dataMethodsDict.items():\n",
    "        for atomA, atomB in atomCombList:\n",
    "            nulltest.run_plot_scatter_explore(f_data_3D, f_metric_cont,\n",
    "                                              atomA, atomB, 3,\n",
    "                                              varLimits=(0, 1), nData=1000, nTestDim=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining testing thresholds for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only test combinations that matter\n",
    "loopLst = [\n",
    "    ['red', 'unq', 'shd_s1_s2', 'unq_s1',    lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, alpha)],\n",
    "    ['red', 'syn', 'shd_s1_s2', 'syn_s1_s2', lambda nData, alpha: null3D.cont_red_noisy(nData, alpha, alpha, 0)],\n",
    "    ['unq', 'red', 'unq_s1',    'shd_s1_s2', lambda nData, alpha: null3D.cont_unq_noisy(nData, alpha, alpha, alpha)]\n",
    "]\n",
    "\n",
    "# TEX + AUD\n",
    "nDataLst = [1315, 1209, 3967, 1910, 1724, 4784, 1307, 1324, 5191, 1132, 1014, 3111] + \\\n",
    "           [1070, 510, 2498, 1274, 735, 3407, 1918, 953, 4472, 1008, 630, 2320] + \\\n",
    "           [564, 591, 605, 643, 812, 1040, 1131, 1166, 1263, 1317, 1406, 1412, 1448,\n",
    "            1525, 1668, 1974, 2438, 2767, 2891, 3228, 3278, 7106, 8209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red_unq_1315 already done\n",
      "red_unq_1209 already done\n",
      "red_unq_3967 already done\n",
      "red_unq_1910 already done\n",
      "red_unq_1724 already done\n",
      "red_unq_4784 already done\n",
      "red_unq_1307 already done\n",
      "red_unq_1324 already done\n",
      "red_unq_5191 already done\n",
      "red_unq_1132 already done\n",
      "red_unq_1014 already done\n",
      "red_unq_3111 already done\n",
      "red_unq_1070 already done\n",
      "red_unq_510 already done\n",
      "red_unq_2498 already done\n",
      "red_unq_1274 already done\n",
      "red_unq_735 already done\n",
      "red_unq_3407 already done\n",
      "red_unq_1918 already done\n",
      "red_unq_953 already done\n",
      "red_unq_4472 already done\n",
      "red_unq_1008 already done\n",
      "red_unq_630 already done\n",
      "red_unq_2320 already done\n",
      "red_unq_564\n",
      "red_unq_591\n",
      "red_unq_605\n",
      "red_unq_643\n",
      "red_unq_812\n",
      "red_unq_1040\n",
      "red_unq_1131\n",
      "red_unq_1166\n",
      "red_unq_1263\n",
      "red_unq_1317\n",
      "red_unq_1406\n",
      "red_unq_1412\n",
      "red_unq_1448\n",
      "red_unq_1525\n",
      "red_unq_1668\n",
      "red_unq_1974\n",
      "red_unq_2438\n",
      "red_unq_2767\n",
      "red_unq_2891\n",
      "red_unq_3228\n",
      "red_unq_3278\n",
      "red_unq_7106\n",
      "red_unq_8209\n",
      "red_syn_1315 already done\n",
      "red_syn_1209 already done\n",
      "red_syn_3967 already done\n",
      "red_syn_1910 already done\n",
      "red_syn_1724 already done\n",
      "red_syn_4784 already done\n",
      "red_syn_1307 already done\n",
      "red_syn_1324 already done\n",
      "red_syn_5191 already done\n",
      "red_syn_1132 already done\n",
      "red_syn_1014 already done\n",
      "red_syn_3111 already done\n",
      "red_syn_1070 already done\n",
      "red_syn_510 already done\n",
      "red_syn_2498 already done\n",
      "red_syn_1274 already done\n",
      "red_syn_735 already done\n",
      "red_syn_3407 already done\n",
      "red_syn_1918 already done\n",
      "red_syn_953 already done\n",
      "red_syn_4472 already done\n",
      "red_syn_1008 already done\n",
      "red_syn_630 already done\n",
      "red_syn_2320 already done\n",
      "red_syn_564\n",
      "red_syn_591\n",
      "red_syn_605\n",
      "red_syn_643\n",
      "red_syn_812\n",
      "red_syn_1040\n",
      "red_syn_1131\n",
      "red_syn_1166\n",
      "red_syn_1263\n",
      "red_syn_1317\n",
      "red_syn_1406\n",
      "red_syn_1412\n",
      "red_syn_1448\n",
      "red_syn_1525\n",
      "red_syn_1668\n",
      "red_syn_1974\n",
      "red_syn_2438\n",
      "red_syn_2767\n",
      "red_syn_2891\n",
      "red_syn_3228\n",
      "red_syn_3278\n",
      "red_syn_7106\n",
      "red_syn_8209\n",
      "unq_red_1315 already done\n",
      "unq_red_1209 already done\n",
      "unq_red_3967 already done\n",
      "unq_red_1910 already done\n",
      "unq_red_1724 already done\n",
      "unq_red_4784 already done\n",
      "unq_red_1307 already done\n",
      "unq_red_1324 already done\n",
      "unq_red_5191 already done\n",
      "unq_red_1132 already done\n",
      "unq_red_1014 already done\n",
      "unq_red_3111 already done\n",
      "unq_red_1070 already done\n",
      "unq_red_510 already done\n",
      "unq_red_2498 already done\n",
      "unq_red_1274 already done\n",
      "unq_red_735 already done\n",
      "unq_red_3407 already done\n",
      "unq_red_1918 already done\n",
      "unq_red_953 already done\n",
      "unq_red_4472 already done\n",
      "unq_red_1008 already done\n",
      "unq_red_630 already done\n",
      "unq_red_2320 already done\n",
      "unq_red_564\n",
      "unq_red_591\n",
      "unq_red_605\n",
      "unq_red_643\n",
      "unq_red_812\n",
      "unq_red_1040\n",
      "unq_red_1131\n",
      "unq_red_1166\n",
      "unq_red_1263\n",
      "unq_red_1317\n",
      "unq_red_1406\n",
      "unq_red_1412\n",
      "unq_red_1448\n",
      "unq_red_1525\n",
      "unq_red_1668\n",
      "unq_red_1974\n",
      "unq_red_2438\n",
      "unq_red_2767\n",
      "unq_red_2891\n",
      "unq_red_3228\n",
      "unq_red_3278\n",
      "unq_red_7106\n",
      "unq_red_8209\n"
     ]
    }
   ],
   "source": [
    "for labelA, labelB, atomA, atomB, f_data_1D in loopLst:\n",
    "    for nData in nDataLst:\n",
    "        key = labelA + '_' + labelB + '_' + str(nData)\n",
    "        with h5py.File('pid_rand_dist.h5', 'a') as h5f:\n",
    "            if key in h5f.keys():\n",
    "                print(key, 'already done')\n",
    "                continue\n",
    "                \n",
    "        print(key)\n",
    "        \n",
    "        randValues = nulltest.run_1D_scan_bare(f_data_1D, f_metric_cont, atomB,\n",
    "                                               varLimits=(0, 1), nData=nData,\n",
    "                                               nStep=100, nTest=100, nTestResample=10000)[1]\n",
    "        \n",
    "        \n",
    "        with h5py.File('pid_rand_dist.h5', 'a') as h5f:\n",
    "            h5f[key] = randValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
