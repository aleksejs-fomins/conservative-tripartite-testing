{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from idtxl.bivariate_pid import BivariatePID\n",
    "from idtxl.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(x):\n",
    "    x1 = x.copy()\n",
    "    np.random.shuffle(x1)\n",
    "    return x1\n",
    "\n",
    "def bin_data_1D(data, nBins):\n",
    "    boundaries = np.quantile(data, np.linspace(0, 1, nBins + 1))\n",
    "    boundaries[-1] += 1.0E-10\n",
    "    return np.digitize(data, boundaries, right=False) - 1\n",
    "\n",
    "def pid_bin(x,y,z, nBins=4):\n",
    "    dataEff = np.array([\n",
    "        bin_data_1D(x, nBins),\n",
    "        bin_data_1D(y, nBins),\n",
    "        bin_data_1D(z, nBins)\n",
    "    ])\n",
    "    return pid(dataEff)\n",
    "    \n",
    "def pid(dataPS):\n",
    "    settings = {'pid_estimator': 'TartuPID', 'lags_pid': [0, 0]}\n",
    "\n",
    "    dataIDTxl = Data(dataPS, dim_order='ps', normalise=False)\n",
    "    pid = BivariatePID()\n",
    "    rez = pid.analyse_single_target(settings=settings, data=dataIDTxl, target=1, sources=[0,2])\n",
    "    return rez.get_single_target(1)\n",
    "\n",
    "def make_test(datagen_func, nBins=4, nTest=100):\n",
    "    rezDict = {}\n",
    "    rezDict['True'] = {'unq_s1': [], 'unq_s2': [], 'syn_s1_s2': [], 'shd_s1_s2': []}\n",
    "    rezDict['Sh'] = {k: [] for k in rezDict['True'].keys()}\n",
    "\n",
    "    for iTest in range(nTest):\n",
    "        x,y,z = datagen_func()\n",
    "\n",
    "        for kind in ['True', 'Sh']:\n",
    "            yEff = y if kind == 'True' else shuffle(y)\n",
    "\n",
    "            if nBins is None:\n",
    "                rez = pid(np.array([x,yEff,z]))\n",
    "            else:\n",
    "                rez = pid_bin(x,yEff,z, nBins=nBins)\n",
    "\n",
    "            for k in rezDict[kind].keys():\n",
    "                rezDict[kind][k] += [rez[k]]\n",
    "\n",
    "    rezDF = pd.DataFrame()\n",
    "    for kind in ['True', 'Sh']:\n",
    "        for k,v in rezDict[kind].items():\n",
    "            rezTmp = pd.DataFrame({'kind': [kind]*nTest, 'Method':[k]*nTest, 'Value': v})\n",
    "            rezDF = rezDF.append(rezTmp)\n",
    "    \n",
    "    return rezDF\n",
    "\n",
    "def plot_test(df, suptitle=None, logEff=False):\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(12,4))\n",
    "    if suptitle is not None:\n",
    "        fig.suptitle(suptitle)\n",
    "    \n",
    "    ax[0].set_title('Metric Value')\n",
    "    ax[1].set_title('Effect Size')\n",
    "    ax[2].set_title('Fraction Significant')\n",
    "    \n",
    "    sns.violinplot(ax=ax[0], x=\"Method\", y=\"Value\", hue=\"kind\", data=df, scale='width')\n",
    "    \n",
    "    # Calculate effect sizes\n",
    "    dfEffSize = pd.DataFrame()\n",
    "    for method in sorted(set(df['Method'])):\n",
    "        dfMethod = df[df['Method'] == method]\n",
    "        dfMethodTrue = dfMethod[dfMethod['kind'] == 'True']\n",
    "        dfMethodRand = dfMethod[dfMethod['kind'] == 'Sh']\n",
    "        \n",
    "        muRand = np.mean(dfMethodRand['Value'])\n",
    "        stdRand = np.std(dfMethodRand['Value'])\n",
    "        \n",
    "        dfMethodEff = dfMethodTrue.copy()\n",
    "        dfMethodEff['Value'] = (dfMethodEff['Value'] - muRand) / stdRand\n",
    "        \n",
    "        dfEffSize = dfEffSize.append(dfMethodEff)\n",
    "        \n",
    "    sns.violinplot(ax=ax[1], x=\"Method\", y=\"Value\", data=dfEffSize, scale='width')\n",
    "    if logEff:\n",
    "        ax[1].set_yscale('log')\n",
    "    #ax[1].axhline(y='2', color='pink', linestyle='--')\n",
    "    \n",
    "    # Calculate fraction significant\n",
    "    sigDict = {}\n",
    "    for method in sorted(set(df['Method'])):\n",
    "        dfEffMethod = dfEffSize[dfEffSize['Method'] == method]\n",
    "        sigDict[method] = [np.mean(dfEffMethod['Value'] > 2)]\n",
    "    \n",
    "    sns.barplot(ax=ax[2], data=pd.DataFrame(sigDict))\n",
    "    ax[2].set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Redundant Scenario\n",
    "\n",
    "We want to check if white noise added to a purely redundant scenario results in correct identification of redundancy\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = T + \\nu_Z$$\n",
    "\n",
    "where $Y$ is the target of $X$ and $Z$, and\n",
    "\n",
    "$$T \\sim \\mathcal{N}(0, 1)$$\n",
    "$$\\nu_X, \\nu_Y, \\nu_Z \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "and $\\sigma$ is a free parameter, denoting the Noise-To-Signal ratio. So the signal should be a mixture of redundant signal and white noise.\n",
    "\n",
    "Since the signal is continuous, we bin it using different bin counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_red_noisy(n=1000, sigErrX=1, sigErrY=1, sigErrZ=1):\n",
    "    t = np.random.normal(0,1,n)\n",
    "    x = t + np.random.normal(0,sigErrX,n)\n",
    "    y = t + np.random.normal(0,sigErrY,n)\n",
    "    z = t + np.random.normal(0,sigErrZ,n)\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing binning-dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezDFDict = {}\n",
    "for nBins in range(2, 6):\n",
    "    gen_data_eff = lambda: gen_data_red_noisy(n=10000, sigErrX=1, sigErrY=1, sigErrZ=1)\n",
    "    rezDFDict[nBins] = make_test(gen_data_eff, nBins=nBins, nTest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for nBins, rezDF in rezDFDict.items():\n",
    "    plot_test(rezDF, suptitle='nBins = ' + str(nBins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relationship of synergy and redundancy for fixed data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezSynLst = []\n",
    "rezRedLst = []\n",
    "\n",
    "for nTest in range(20000):\n",
    "    if nTest % 1000 == 0:\n",
    "        print(nTest)\n",
    "    \n",
    "    sigErrX, sigErrY, sigErrZ = np.random.uniform(0, 2, 3)\n",
    "    x, y, z = gen_data_red_noisy(n=1000, sigErrX=sigErrX, sigErrY=sigErrY, sigErrZ=sigErrZ)\n",
    "    rez = pid_bin(x,y,z, nBins=4)\n",
    "    \n",
    "    rezSynLst += [rez['syn_s1_s2']]\n",
    "    rezRedLst += [rez['shd_s1_s2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rezRedLst, rezSynLst, '.')\n",
    "plt.xlabel('Redundancy')\n",
    "plt.ylabel('Synergy')\n",
    "plt.title('Synergy-Redundancy relationship for noisy redundant model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Unique Scenario\n",
    "\n",
    "We want to check if white noise added to a purely unique information scenario results in correct identification of redundancy\n",
    "\n",
    "$$X = T + \\nu_X$$\n",
    "$$Y = T + \\nu_Y$$\n",
    "$$Z = \\nu_Z$$\n",
    "\n",
    "where $Y$ is the target of $X$ and $Z$, and\n",
    "\n",
    "$$T \\sim \\mathcal{N}(0, 1)$$\n",
    "$$\\nu_X, \\nu_Y, \\nu_Z \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "and $\\sigma$ is a free parameter, denoting the Noise-To-Signal ratio. So the signal should be a mixture of redundant signal and white noise.\n",
    "\n",
    "Since the signal is continuous, we bin it using different bin counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data_unq_noisy(n=1000, sigErr=1):\n",
    "    t = np.random.normal(0,1,n)\n",
    "    x = t + np.random.normal(0,sigErr,n)\n",
    "    y = t + np.random.normal(0,sigErr,n)\n",
    "    z = np.random.normal(0,sigErr,n)\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezDFDict = {}\n",
    "for nBins in range(2, 6):\n",
    "    gen_data_eff = lambda: gen_data_unq_noisy(n=10000, sigErr=1)\n",
    "    rezDFDict[nBins] = make_test(gen_data_eff, nBins=nBins, nTest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for nBins, rezDF in rezDFDict.items():\n",
    "    plot_test(rezDF, suptitle='nBins = ' + str(nBins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Redundant Scenario - Discrete Case\n",
    "\n",
    "It is important to test if false positives are caused by binning, or are an intrinsic property of the noise in the covariate. Here I propose a discretized noisy redundancy model. Instead of added noise, each variable has a random chance to produce the redundant outcome or a purely random outcome.\n",
    "\n",
    "$$X \\sim A_X T + (1 - A_X) \\nu_X $$\n",
    "$$Y \\sim A_Y T + (1 - A_Y) \\nu_Y $$\n",
    "$$Z \\sim A_Z T + (1 - A_Z) \\nu_Z $$\n",
    "\n",
    "where\n",
    "\n",
    "$$T, \\nu_X, \\nu_Y, \\nu_Z \\sim Ber(0.5) $$\n",
    "$$A_X \\sim Ber(\\alpha_X)$$\n",
    "$$A_Y \\sim Ber(\\alpha_Y)$$\n",
    "$$A_Z \\sim Ber(\\alpha_Z)$$\n",
    "\n",
    "and $\\alpha_X, \\alpha_Y, \\alpha_Z \\in [0, 1]$ are flexible.\n",
    "\n",
    "So, $\\alpha = 0$ means purely noisy signal, and $\\alpha=1$ means purely redundant signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bernoulli(n, p):\n",
    "    return (np.random.uniform(0, 1, n) < p).astype(int)\n",
    "\n",
    "def gen_discrete_random(nSample, alphaX=0.5, alphaY=0.5, alphaZ=0.5):\n",
    "    T = bernoulli(nSample, 0.5)\n",
    "    nuX = bernoulli(nSample, 0.5)\n",
    "    nuY = bernoulli(nSample, 0.5)\n",
    "    nuZ = bernoulli(nSample, 0.5)\n",
    "    aX = bernoulli(nSample, alphaX)\n",
    "    aY = bernoulli(nSample, alphaY)\n",
    "    aZ = bernoulli(nSample, alphaZ)\n",
    "    \n",
    "    x = aX*T + (1 - aX)*nuX\n",
    "    y = aY*T + (1 - aY)*nuY\n",
    "    z = aZ*T + (1 - aZ)*nuZ\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaLst = np.linspace(0, 1, 10)\n",
    "\n",
    "rezDFDict = {}\n",
    "for alpha in alphaLst:\n",
    "    gen_data_eff = lambda: gen_discrete_random(nSample=10000, alphaX=alpha, alphaY=alpha, alphaZ=alpha)\n",
    "    rezDFDict[alpha] = make_test(gen_data_eff, nBins=None, nTest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pAlpha, rezDF in rezDFDict.items():\n",
    "    plot_test(rezDF, suptitle='alpha = ' + str(pAlpha), logEff=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Asymptotic behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSampleLst = (10**np.linspace(2, 5, 10)).astype(int)\n",
    "\n",
    "rezDFDict = {}\n",
    "for nSample in nSampleLst:\n",
    "    gen_data_eff = lambda: gen_discrete_random(nSample=nSample, alphaX=0.9, alphaY=0.9, alphaZ=0.9)\n",
    "    rezDFDict[nSample] = make_test(gen_data_eff, nBins=None, nTest=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in ['True', 'Sh']:\n",
    "    muTrueDict = defaultdict(list)\n",
    "    stdTrueDict = defaultdict(list)\n",
    "\n",
    "    for nSample, df in rezDFDict.items():\n",
    "        for method in sorted(set(df['Method'])):\n",
    "            dfMethod = df[df['Method'] == method]\n",
    "            dfMethodTrue = dfMethod[dfMethod['kind'] == kind]\n",
    "\n",
    "            muTrueDict[method] += [np.mean(dfMethodTrue['Value'])]\n",
    "            stdTrueDict[method] += [np.std(dfMethodTrue['Value'])]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for method, muTrueLst in muTrueDict.items():\n",
    "        plt.errorbar(nSampleLst, muTrueLst, stdTrueDict[method], label=method)\n",
    "\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title(kind)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relationship of synergy and redundancy for fixed data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezSynLst = []\n",
    "rezRedLst = []\n",
    "\n",
    "for nTest in range(20000):\n",
    "    alphaX, alphaY, alphaZ = np.random.uniform(0.6, 1, 3)\n",
    "    x,y,z = gen_discrete_random(nSample=1000, alphaX=alphaX, alphaY=alphaY, alphaZ=alphaZ)\n",
    "    rez = pid(np.array([x,y,z]))\n",
    "    rezSynLst += [rez['syn_s1_s2']]\n",
    "    rezRedLst += [rez['shd_s1_s2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rezRedLst, rezSynLst, '.')\n",
    "plt.xlabel('Redundancy')\n",
    "plt.ylabel('Synergy')\n",
    "plt.title('Synergy-Redundancy relationship for noisy redundant model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3ml",
   "language": "python",
   "name": "py3ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
